{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    s = 1/(1 + np.exp(-x))\n",
    "    return s\n",
    "def tanh(x):\n",
    "    s = (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "    return s\n",
    "def sigmoid_grad(x):\n",
    "    s = sigmoid(x)\n",
    "    s_grad = s * (1-s)\n",
    "    return s_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 64, 64, 3)\n",
      "Train x dataset: (12288, 209)\n",
      "Train y dataset: (1, 209)\n",
      "Test x dataset: (12288, 50)\n",
      "Test y dataset: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "train_path = 'data/train_catvnoncat.h5'\n",
    "test_path = 'data/test_catvnoncat.h5'\n",
    "\n",
    "def load_data(train_path, test_path):\n",
    "    train_dataset = h5py.File(train_path,'r')\n",
    "    train_set_X = np.array(train_dataset['train_set_x'][:])\n",
    "    train_set_Y = np.array(train_dataset['train_set_y'][:])\n",
    "\n",
    "    test_dataset = h5py.File(test_path,'r')\n",
    "    test_set_X = np.array(test_dataset['test_set_x'][:])\n",
    "    test_set_Y = np.array(test_dataset['test_set_y'][:])\n",
    "    classes = np.array(test_dataset['list_classes'][:])\n",
    "    return train_set_X, train_set_Y, test_set_X, test_set_Y, classes\n",
    "\n",
    "train_set_X, train_set_Y, test_set_X, test_set_Y, classes = load_data(train_path, test_path)\n",
    "print (train_set_X.shape)\n",
    "\n",
    "# reshape data to vector\n",
    "def reshape_data(x_dataset, y_dataset):\n",
    "    x_dataset_reshape = x_dataset.reshape((x_dataset.shape[1] * x_dataset.shape[2] * x_dataset.shape[3],x_dataset.shape[0]))\n",
    "    y_dataset_reshape = y_dataset.reshape((1,y_dataset.shape[0]))\n",
    "    return x_dataset_reshape, y_dataset_reshape\n",
    "\n",
    "# Run the function to check the errors\n",
    "train_set_X_reshape, train_set_Y_reshape = reshape_data(train_set_X, train_set_Y)\n",
    "test_set_X_reshape, test_set_Y_reshape = reshape_data(test_set_X,test_set_Y)\n",
    "print('Train x dataset: ' + (str(train_set_X_reshape.shape)))\n",
    "print('Train y dataset: ' + (str(train_set_Y_reshape.shape)))\n",
    "print('Test x dataset: ' + (str(test_set_X_reshape.shape)))\n",
    "print('Test y dataset: ' + (str(test_set_Y_reshape.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Define three variables: n_x, n_h, n_y are the size of input layer, the size of\n",
    "hidden layer and the size of the output layer, respective. In this exercise, we hardly set\n",
    "the hidden layer size to be 4 (n_h=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input: 12288\n",
      "Hidden nodes: 4\n",
      "Size of output: 1\n"
     ]
    }
   ],
   "source": [
    "#give the input parameters of model\n",
    "def layer_sizes(X,Y,hidden_nodes = 4):\n",
    "    n_x = X.shape[0]\n",
    "    n_h = hidden_nodes\n",
    "    n_y = Y.shape[0]\n",
    "    return (n_x, n_h, n_y) \n",
    "\n",
    "# test the function:\n",
    "input_size, hidden_nodes, output_size = layer_sizes(train_set_X_reshape,train_set_Y_reshape, hidden_nodes = 4)\n",
    "print('Size of input: %s' %(input_size))\n",
    "print('Hidden nodes: %s' %(hidden_nodes))\n",
    "print('Size of output: %s' %(output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Implement *initialize_parameters()* function. You have to initialize w and\n",
    "b parameters as random matrix using numpy library (not zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialzie the parameters values by using random value (instead of 0 values)\n",
    "\n",
    "def initialize_parameters(n_x, n_h,n_y):\n",
    "    np.random.seed(2)\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h) * 0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    params = {'W1': W1, 'b1':b1, 'W2':W2, 'b2':b2}\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Implement the *forward_propagation()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,params):\n",
    "    # Load the parameters\n",
    "    W1 = params['W1']\n",
    "    W2 = params['W2']\n",
    "    b1 = params['b1']\n",
    "    b2 = params['b2']\n",
    "    \n",
    "    # Computing the values for the first layer\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    \n",
    "    # Computing for the second layer\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache = {'Z1':Z1, 'A1':A1, 'Z2':Z2, 'A2':A2}\n",
    "    return A2,cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** Implement the *compute_cost()* function to compute the cost value ð½."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, params):\n",
    "    m = Y.shape[1] # number of examples\n",
    "    log_probs = np.multiply(np.log(A2),Y) + np.multiply(np.log(1-A2), (1-Y))\n",
    "    cost = - np.sum(log_probs)/m\n",
    "    cost = np.squeeze(cost) #Remove single-dimensional entries from the shape of an array.\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** Implement the *backward_propagation()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X,Y, params, cache):\n",
    "    m = X.shape[1] # number of examples\n",
    "    W1, W2 = params['W1'], params['W2']\n",
    "    A1, A2 = cache['A1'], cache['A2']\n",
    "    \n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2, A1.T)/m\n",
    "    db2 = np.sum(dZ2, axis = 1, keepdims = True)/m\n",
    "    d_gz = 1 - np.power(A1,2)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * d_gz\n",
    "    dW1 = np.dot(dZ1, X.T)/m\n",
    "    db1 = np.sum(dZ1, axis = 1, keepdims = True)/m\n",
    "    \n",
    "    grads = {'dW1':dW1, 'db1':db1, 'dW2':dW2, 'db2':db2}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** Implement the *update_rule()* function to update the parameters of your\n",
    "network. This functions have to use (dW1, db1, dW2, db2) in order to update the value\n",
    "of (W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rule(params, grads, learning_rate):\n",
    "    W1, W2 = params['W1'], params['W2']\n",
    "    b1, b2 = params['b1'], params['b2']\n",
    "    dW1, dW2 = grads['dW1'], grads['dW2']\n",
    "    db1, db2 = grads['db1'], grads['db2']\n",
    "    \n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    \n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    \n",
    "    params = {'W1': W1, 'W2':W2, 'b1':b1, 'b2':b2}\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** Merge together the functions that you have implemented for your network\n",
    "into *nn_one_hidden_model()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all step into a function\n",
    "\n",
    "def nn_one_hidden_model(X,Y, hidden_nodes, learning_rate, num_iteration = 2000):\n",
    "    np.random.seed(3)\n",
    "    # get the number of input size, hidden nodes, output size\n",
    "    n_x = layer_sizes(X,Y, hidden_nodes)[0]\n",
    "    n_y = layer_sizes(X,Y,hidden_nodes)[2]\n",
    "    \n",
    "    # initialize the parameters of layers by using (input size, hidden nodes, output size)\n",
    "    params = initialize_parameters(n_x, hidden_nodes, n_y)\n",
    "    W1, W2 = params['W1'], params['W2']\n",
    "    b1, b2 = params['b1'], params['b2']\n",
    "    \n",
    "    # begin to train in num_iteration round\n",
    "    for i in range(0,num_iteration):\n",
    "        # calculatge the forward direction\n",
    "        A2, cache = forward_propagation(X, params)\n",
    "        # compute the cost\n",
    "        cost = compute_cost(A2, Y, params)\n",
    "        # calculate the backward direction (derivatives of w(i) and b(i))\n",
    "        grads = backward_propagation(X, Y, params, cache)\n",
    "        # update the parameters (w1, b1, w2, b2)\n",
    "        params = update_rule(params, grads, learning_rate)\n",
    "        \n",
    "        if i% 500 == 0:\n",
    "            print('Cost after iteration %i: %f' %(i, cost))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.697198\n",
      "Cost after iteration 500: 0.643974\n",
      "Cost after iteration 1000: 0.643974\n",
      "Cost after iteration 1500: 0.643974\n",
      "Cost after iteration 2000: 0.643974\n",
      "Cost after iteration 2500: 0.643974\n"
     ]
    }
   ],
   "source": [
    "# Traing the network with dataset\n",
    "params = nn_one_hidden_model(train_set_X_reshape,train_set_Y_reshape,hidden_nodes = 4, learning_rate = 0.01, num_iteration = 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:** Implement the *prediction()* function to use your model to predict the test\n",
    "examples. Then, comparing the result with the result of Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34%\n"
     ]
    }
   ],
   "source": [
    "def prediction(X_test, parameters):\n",
    "    A2, cache = forward_propagation(X_test, parameters)\n",
    "    predictions = A2 > 0.5\n",
    "    return predictions\n",
    "\n",
    "predictions = prediction(test_set_X_reshape, params)\n",
    "print ('Accuracy: %d' % float((np.dot(test_set_Y_reshape,predictions.T) + np.dot(1-test_set_Y_reshape,1-predictions.T))/float(test_set_Y_reshape.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** Change the size of hidden layer and re-run the model (i.e. 5, 10, 20, 50).\n",
    "Then, comparing the results of model among different number of hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693367\n",
      "Cost after iteration 500: 0.626581\n",
      "Cost after iteration 1000: 0.624817\n",
      "Cost after iteration 1500: 0.617724\n",
      "Cost after iteration 2000: 0.612264\n",
      "Cost after iteration 2500: 0.608308\n",
      "Accuracy: 34%\n"
     ]
    }
   ],
   "source": [
    "params = nn_one_hidden_model(train_set_X_reshape,train_set_Y_reshape,hidden_nodes = 100, learning_rate = 0.01, num_iteration = 3000)\n",
    "predictions = prediction(test_set_X_reshape, params)\n",
    "print ('Accuracy: %d' % float((np.dot(test_set_Y_reshape,predictions.T) + np.dot(1-test_set_Y_reshape,1-predictions.T))/float(test_set_Y_reshape.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
